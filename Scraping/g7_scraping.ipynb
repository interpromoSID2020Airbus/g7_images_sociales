{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Fri Jan 10 11:06:30 2020\n",
    "<br>\n",
    "Group 7\n",
    "<br>\n",
    "@author: C.L.\n",
    "\n",
    "<h1>Group 7 - Images sociales<span class=\"tocSkip\"></span>\n",
    "    \n",
    "<br>  \n",
    "<center>Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Parameters</a></span></li></ul></li><li><span><a href=\"#Airliners\" data-toc-modified-id=\"Airliners-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Airliners</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Extract-images-info\" data-toc-modified-id=\"Extract-images-info-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Extract images info</a></span></li><li><span><a href=\"#Retreive-and-save-images\" data-toc-modified-id=\"Retreive-and-save-images-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Retreive and save images</a></span></li></ul></li><li><span><a href=\"#Google-images\" data-toc-modified-id=\"Google-images-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Google images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Extract-info,-retreive-and-save-images\" data-toc-modified-id=\"Extract-info,-retreive-and-save-images-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Extract info, retreive and save images</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know before scraping : Airliners images are protected by copyright.\n",
    "\n",
    "In order to train a model able to recognize aircraft types from the outside, we needed training images.\n",
    "For this purpose, we scrapped images from Airliners and Google Images. The method for one website is the following:\n",
    "* Extract relevant web links, and store them into a DataFrame (saved as `CSV`);\n",
    "* Use these DataFrames to extract and store images.\n",
    "\n",
    "Running the following code takes a bit of time. Since we already performed this scraping task, you don't need to run it again (that said, you can use the code as a template and adapt it to other websites you might want to srcap)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "To ensure a proper functioning of this code file, `python 3.6` or later version is required.\n",
    "\n",
    "Please note that Google Images scraping requires the installation of `ChromeDriver`: https://chromedriver.chromium.org/.\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import csv\n",
    "from PIL import Image\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import numpy as np\n",
    "import errno\n",
    "import os\n",
    "import urllib.request\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selenium 3.141.0\n",
      "bs4 4.8.1\n",
      "PIL 6.2.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p selenium,bs4,PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "project_path = './../'\n",
    "scrap_path = project_path + 'Scraping/'\n",
    "airliners_csv_path = scrap_path + 'Airliners/'\n",
    "airliners_path = airliners_csv_path + 'data/'\n",
    "google_path = scrap_path + 'Google_img/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airliners\n",
    "Boeing : 28482 pages found\n",
    "<br>\n",
    "Airbus : 17453 pages found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(path: str):\n",
    "    \"\"\"Creates directories to store Airbus and Boeing scrapped images\"\"\"\n",
    "    os.makedirs(path + 'Airbus', exist_ok=True)\n",
    "    os.makedirs(path + 'Boeing', exist_ok=True)\n",
    "\n",
    "\n",
    "def get_photos_name_page(link: str) -> pd.DataFrame:\n",
    "    \"\"\"From a given Airliner link, creates a DataFrame containing, for each image found:\n",
    "        - link to the image\n",
    "        - manufacturer\n",
    "        - aircraft type \n",
    "        - a more precise designation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    req = requests.get(link)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "    AirCrafts = soup.find_all(\"div\", {\"class\": \"ps-v2-results-row\"})\n",
    "    list_DF = []\n",
    "\n",
    "    for air in AirCrafts:\n",
    "        try:\n",
    "            photo = air.find_all(\"img\")[0].attrs['src']\n",
    "            details_cell = air.find_all(\n",
    "                \"div\", {\"class\": \"ps-v2-results-col ps-v2-results-col-aircraft\"})[0]\n",
    "            details_cell = details_cell.find_all(\n",
    "                \"div\", {'class': \"ps-v2-results-col-content\"})[0]\n",
    "            details_cell = details_cell.find_all(\n",
    "                \"div\", {\"class\": \"ps-v2-results-col-content-primary\"})[0]\n",
    "            name_cell = details_cell.find_all(\n",
    "                \"div\", {\"class\": \"ps-v2-results-display-detail-no-wrapping\"})[1]\n",
    "            name = name_cell.a.text.strip().replace('/', '-')\n",
    "            if name.split()[0] in ['Airbus', 'Boeing']:\n",
    "                list_DF.append(\n",
    "                    [photo, name.split()[0], name.split()[1].split('-')[0], name])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    DF = pd.DataFrame(list_DF, columns=[\n",
    "                      'Photo', 'Manufacturer', 'Aircraft_type', 'Designation'])\n",
    "\n",
    "    return(DF)\n",
    "\n",
    "\n",
    "def create_df_manufacturer(a: int, b: int, man_name: str) -> pd.DataFrame:\n",
    "    \"\"\"For a given manufacturer, creates a DataFrame in which each line contains information related to an aircraft \n",
    "    image.\n",
    "\n",
    "    Parameters: \n",
    "        a: page number where the search begins\n",
    "        b: page number where the search ends\n",
    "        man_name: aircraft manufacturer name\n",
    "\n",
    "    Out:\n",
    "        df: DataFrame with retreived information\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    l_df = []\n",
    "    dic_code_man = {'Airbus': '2', 'Boeing': '7'}\n",
    "    for i in range(a, b):\n",
    "        print(i)\n",
    "        link = 'https://www.airliners.net/search?aircraftManufacturer=' + dic_code_man[man_name] + \\\n",
    "               '&photoCategory=23&sortBy=dateAccepted&sortOrder=desc&perPage=36&display=detail&page=' + \\\n",
    "            str(i)\n",
    "        l_df.append(get_photos_name_page(link))\n",
    "    df = pd.concat(l_df, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_df_passengers(df: pd.DataFrame, manufacturer: str, dic_type: dict):\n",
    "    \"\"\"Creates a new DataFrame with only rows matching with commercial aircraft and adds a column\n",
    "    similar to the index.\n",
    "\n",
    "    Parameters : \n",
    "        df: DataFrame on which the selection must be proceed\n",
    "        manufacturer: company name ('Airbus' or 'Boeing')\n",
    "        dic_type: keys are companies names and values are lists of the commercial aircraft of the manufacturer \n",
    "\n",
    "    Out :\n",
    "        df_passengers: modified DataFrame \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df_passengers = df[df['Aircraft_type'].isin(dic_type[manufacturer])]\n",
    "\n",
    "    return df_passengers.assign(Number=df_passengers.index)\n",
    "\n",
    "\n",
    "def get_nb_imgs_per_type(df: pd.DataFrame, nb: int, a: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        df: DataFrame with only aircraft types of interest\n",
    "        nb: number of images to create for each aircraft type\n",
    "        a: lag\n",
    "\n",
    "    Out:\n",
    "        df_nb: DataFrame containing the number of images per aircraft type. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # nb :\n",
    "    ix = []\n",
    "    for el in df['Aircraft_type'].unique().tolist():\n",
    "        df_el = df[df['Aircraft_type'] == el].copy()\n",
    "        df_el.reset_index(drop=True, inplace=True)\n",
    "        df_el = df_el.loc[a: a + min(nb-1, len(df_el))]\n",
    "        ix.extend(df_el['Number'].tolist())\n",
    "    df_nb = df[df['Number'].isin(ix)]\n",
    "\n",
    "    return df_nb\n",
    "\n",
    "\n",
    "def get_from_link_and_write(df: pd.DataFrame, man: str, path: str):\n",
    "    \"\"\"Retreives and saves images.\n",
    "\n",
    "    Parameters:\n",
    "        df: DataFrame with links of images to scrap\n",
    "        man: aircraft manufacturer\n",
    "        path: where to save images\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for el in df['Aircraft_type'].unique().tolist():\n",
    "        df_type = df[df['Aircraft_type'] == el]\n",
    "        fold_name = path + man + '/' + el\n",
    "        os.makedirs(fold_name, exist_ok=True)\n",
    "        my_rows = zip(df_type['Number'], df_type['Photo'])\n",
    "        for (num, photo) in my_rows:\n",
    "            img_data = requests.get(photo).content\n",
    "            try:\n",
    "                i = Image.open(io.BytesIO(img_data))\n",
    "                i.save(fold_name + '/' + man +\n",
    "                       '_' + str(num) + '_' + el + '.jpg')\n",
    "            except:\n",
    "                print(el, num)\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract images info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Airbus and Boeing directories where to save images\n",
    "create_directories(airliners_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following code blocks takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap Airbus images\n",
    "df_boeing_airliners = create_df_manufacturer(\n",
    "    1, 500, 'Airbus')  # retreive info\n",
    "df_boeing_airliners.to_csv(\n",
    "    scrap_path + 'Airbus_Airliners.csv', sep=';', index=False)  # save to csv\n",
    "len(df_airbus_airliners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap Boeing images\n",
    "df_boeing_airliners = create_df_manufacturer(\n",
    "    1, 500, 'Boeing')  # retreive info\n",
    "df_boeing_airliners.to_csv(\n",
    "    scrap_path + 'Boeing_Airliners.csv', sep=';', index=False)  # save to csv\n",
    "len(df_airbus_airliners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to retreive DataFrames from csv if need be\n",
    "df_airbus = pd.read_csv(scrap_path + 'Airbus_Airliners.csv', sep=';')\n",
    "df_boeing = pd.read_csv(scrap_path + 'Boeing_Airliners.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict with aircraft types for each manufacturer\n",
    "dic_type = {'Airbus': ['A220',\n",
    "                       'A300B4',\n",
    "                       'A310',\n",
    "                       'A318',\n",
    "                       'A319',\n",
    "                       'A320',\n",
    "                       'A321',\n",
    "                       'A330',\n",
    "                       'A340',\n",
    "                       'A350',\n",
    "                       'A380'\n",
    "                       ],\n",
    "            'Boeing': ['717',\n",
    "                       '727',\n",
    "                       '737',\n",
    "                       '747',\n",
    "                       '757',\n",
    "                       '767',\n",
    "                       '777',\n",
    "                       '787'\n",
    "                       ]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates new DataFrames with only rows matching with commercial aircraft\n",
    "df_airbus_passengers = create_df_passengers(df_airbus, 'Airbus', dic_type)\n",
    "df_boeing_passengers = create_df_passengers(df_boeing, 'Boeing', dic_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of elements per aircraft type\n",
    "for el in dic_type['Airbus']:\n",
    "    print(el, len(df_airbus[df_airbus['Aircraft_type'] == el]))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for el in dic_type['Boeing']:\n",
    "    print(el, len(df_boeing[df_boeing['Aircraft_type'] == el]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreive and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airbus\n",
    "df_airbus_limited = get_nb_imgs_per_type(df_airbus_passengers, 500, 0)\n",
    "print(len(df_airbus_100))\n",
    "\n",
    "start = time.time()\n",
    "get_from_link_and_write(df_airbus_limited, 'Airbus', airliners_path)\n",
    "print(time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boeing\n",
    "df_boeing_limited = get_nb_imgs_per_type(df_boeing_passengers, 500, 0)\n",
    "get_from_link_and_write(df_boeing_limited, 'Boeing', airliners_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_img_by_aircraft_type(aircraft_type: str, dic_df_types: dict):\n",
    "    \"\"\" Updates a dictionary with a DataFrame giving links to the pictures found on the\n",
    "    first Google Images page for a given request.\n",
    "\n",
    "    Parameters :\n",
    "        aircraft_type: request for Google Images, e.g.: 'Airbus A380'.\n",
    "        dic_df_types: keys = aircraft_type; values = DataFrames.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Use of &tbs=sur:fc in the link to download only free_to_use images:\n",
    "    link = 'https://www.google.com/search?q=' + \\\n",
    "        aircraft_type + \"&tbm=isch&tbs=sur:fc\"\n",
    "    df_images = pd.DataFrame(columns=[\"link\", \"request\", \"source\", \"source_2\"])\n",
    "    driver.get(link)\n",
    "    time.sleep(5)\n",
    "\n",
    "    blocks_images = driver.find_elements_by_xpath(\n",
    "        \"//div[contains(@class,'rg_bx rg_di rg_el ivg-i')]\")\n",
    "    for bi in blocks_images:\n",
    "\n",
    "        site = bi.find_elements_by_xpath(\".//span\")\n",
    "        if site:\n",
    "            site = site[0].get_attribute(\"innerHTML\")\n",
    "\n",
    "        source_1 = bi.find_elements_by_xpath(\".//img\")\n",
    "        if source_1:\n",
    "            source_1 = source_1[0].get_attribute(\"data-src\")\n",
    "\n",
    "        source_2 = bi.find_elements_by_xpath(\"./a\")\n",
    "        if source_2:\n",
    "            source_2 = source_2[0].get_attribute(\"href\")\n",
    "\n",
    "        row = pd.Series([site, aircraft_type, source_1,\n",
    "                         source_2], index=df_images.columns)\n",
    "        df_images = df_images.append(row, ignore_index=True, sort=False)\n",
    "\n",
    "    dic_df_types[aircraft_type] = df_images\n",
    "\n",
    "\n",
    "def get_from_source_and_write(request: str, dic_df_types: dict, path: str):\n",
    "    \"\"\"Retreives and saves images.\n",
    "\n",
    "    Parameters:\n",
    "        request: manufacturer name + white space + aircraft-type (e.g.: 'Airbus A320')\n",
    "        dic_df_types: \n",
    "        path: path to the Google subdirectory\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(request)\n",
    "    df = dic_df_types[request]\n",
    "    print(len(df))\n",
    "    df = df[df['source'].notnull()]\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.assign(Number=df.index)\n",
    "    print(len(df))\n",
    "    request = request.split()\n",
    "    fold_name = path + request[0] + '/' + request[1]\n",
    "    os.makedirs(fold_name, exist_ok=True)\n",
    "    my_rows = zip(df['Number'], df['source'])\n",
    "    for (num, source) in my_rows:\n",
    "        img_data = requests.get(source).content\n",
    "        try:\n",
    "            i = Image.open(io.BytesIO(img_data))\n",
    "            i.save(fold_name + '/' +\n",
    "                   request[0] + '_' + request[1] + '_' + str(num) + '.jpg')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Chrome Driver and create Airbus and Boeing directories where to save images\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "os.makedirs(google_path, exist_ok=True)\n",
    "\n",
    "# Init\n",
    "dic_df_types = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract info, retreive and save images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following code blocks takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the dict with links to the pictures to scrap\n",
    "for key in dic_type.keys():\n",
    "    print(key)\n",
    "    for aircraft in dic_type[key]:\n",
    "        print(aircraft)\n",
    "        google_img_by_aircraft_type(key + ' ' + aircraft, dic_df_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive and save images\n",
    "for key in dic_type.keys():\n",
    "    for aircraft in dic_type[key]:\n",
    "        get_from_source_and_write(\n",
    "            key + ' ' + aircraft, dic_df_types, google_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames to csv\n",
    "for key, val in dic_df_types.items():\n",
    "    val.to_csv(google_path + \"Google_{}.csv\".format(str(key)),\n",
    "               sep=';', index=False)\n",
    "\n",
    "# Save keys to txt file\n",
    "with open(google_path + \"keys.txt\", \"w\") as f:\n",
    "    f.write(str(list(dic_df_types.keys())))\n",
    "\n",
    "# Read data from keys\n",
    "with open(google_path + \"keys.txt\", \"r\") as f:\n",
    "    keys = eval(f.read())\n",
    "    dic = {}\n",
    "    for key in keys:\n",
    "        dic[key] = pd.read_csv(\n",
    "            google_path + \"Google_{}.csv\".format(str(key)), sep=';')\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
